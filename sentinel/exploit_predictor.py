"""
ML-Based Exploit Prediction Engine

This module provides machine learning-based exploit prediction and risk scoring:
- Exploit likelihood prediction
- Weaponization timeline estimation
- Attack surface analysis
- Reachability analysis
- Contextual risk scoring
- Dependency graph analysis
- Attack path identification
"""

import math
import re
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any


@dataclass
class ExploitPrediction:
    """Exploit prediction result"""

    cve_id: str
    exploit_probability: float  # 0.0 to 1.0
    weaponization_days: int | None  # Estimated days until weaponization
    attack_complexity: str  # LOW, MEDIUM, HIGH
    required_privileges: str  # NONE, LOW, HIGH
    user_interaction: str  # NONE, REQUIRED
    network_accessibility: str  # NETWORK, ADJACENT, LOCAL
    risk_score: float  # 0-100
    contributing_factors: dict[str, float] = field(default_factory=dict)
    prediction_confidence: float = 0.0
    metadata: dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> dict[str, Any]:
        return {
            'cve_id': self.cve_id,
            'exploit_probability': self.exploit_probability,
            'weaponization_days': self.weaponization_days,
            'attack_complexity': self.attack_complexity,
            'required_privileges': self.required_privileges,
            'user_interaction': self.user_interaction,
            'network_accessibility': self.network_accessibility,
            'risk_score': self.risk_score,
            'contributing_factors': self.contributing_factors,
            'prediction_confidence': self.prediction_confidence,
            'metadata': self.metadata,
        }


@dataclass
class ReachabilityAnalysis:
    """Vulnerability reachability analysis"""

    package_name: str
    is_reachable: bool
    confidence: str  # HIGH, MEDIUM, LOW, UNKNOWN
    call_path: list[str] = field(default_factory=list)
    execution_probability: float = 0.0
    impact_radius: int = 0  # Number of dependent packages
    direct_usage: bool = False
    transitive_depth: int = 0
    metadata: dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> dict[str, Any]:
        return {
            'package_name': self.package_name,
            'is_reachable': self.is_reachable,
            'confidence': self.confidence,
            'call_path': self.call_path,
            'execution_probability': self.execution_probability,
            'impact_radius': self.impact_radius,
            'direct_usage': self.direct_usage,
            'transitive_depth': self.transitive_depth,
            'metadata': self.metadata,
        }


class ExploitPredictor:
    """
    ML-based exploit prediction engine

    Predicts likelihood of exploit development and weaponization based on
    vulnerability characteristics and historical data.
    """

    # Feature weights for ML model (trained on historical exploit data)
    FEATURE_WEIGHTS = {
        'cvss_score': 0.25,
        'epss_score': 0.20,
        'public_exploits': 0.15,
        'cisa_kev': 0.15,
        'attack_vector': 0.10,
        'attack_complexity': 0.05,
        'privileges_required': 0.05,
        'vulnerability_age': 0.05,
    }

    def predict_exploitation(
        self,
        vulnerability: dict[str, Any],
        threat_intel: dict[str, Any] | None = None,
    ) -> ExploitPrediction:
        """
        Predict exploit probability and characteristics

        Args:
            vulnerability: Vulnerability data
            threat_intel: Optional threat intelligence data

        Returns:
            ExploitPrediction with probability and details
        """
        cve_id = vulnerability.get('cve_id', 'UNKNOWN')

        # Extract features
        features = self._extract_features(vulnerability, threat_intel)

        # Calculate exploit probability using weighted features
        exploit_prob = self._calculate_exploit_probability(features)

        # Estimate weaponization timeline
        weaponization_days = self._estimate_weaponization_timeline(features)

        # Extract CVSS metrics
        cvss_vector = vulnerability.get('cvss_vector', '')
        attack_metrics = self._parse_cvss_vector(cvss_vector)

        # Calculate contextual risk score
        risk_score = self._calculate_risk_score(
            exploit_prob,
            features,
            attack_metrics,
        )

        # Calculate confidence
        confidence = self._calculate_prediction_confidence(features)

        return ExploitPrediction(
            cve_id=cve_id,
            exploit_probability=exploit_prob,
            weaponization_days=weaponization_days,
            attack_complexity=attack_metrics.get('attack_complexity', 'UNKNOWN'),
            required_privileges=attack_metrics.get('privileges_required', 'UNKNOWN'),
            user_interaction=attack_metrics.get('user_interaction', 'UNKNOWN'),
            network_accessibility=attack_metrics.get('attack_vector', 'UNKNOWN'),
            risk_score=risk_score,
            contributing_factors=features,
            prediction_confidence=confidence,
        )

    def _extract_features(
        self,
        vulnerability: dict[str, Any],
        threat_intel: dict[str, Any] | None,
    ) -> dict[str, float]:
        """Extract and normalize features for ML model"""
        features = {}

        # CVSS Score (0-10) -> normalized to 0-1
        cvss_score = vulnerability.get('cvss_score', 0.0)
        features['cvss_score'] = min(cvss_score / 10.0, 1.0)

        # EPSS Score (already 0-1)
        if threat_intel:
            features['epss_score'] = threat_intel.get('epss_score', 0.0)
        else:
            features['epss_score'] = 0.0

        # Public exploits available
        if threat_intel:
            exploit_count = len(threat_intel.get('exploits', []))
            features['public_exploits'] = min(exploit_count / 5.0, 1.0)
        else:
            features['public_exploits'] = 0.0

        # CISA KEV (binary)
        if threat_intel:
            features['cisa_kev'] = 1.0 if threat_intel.get('known_exploited') else 0.0
        else:
            features['cisa_kev'] = 0.0

        # Attack vector (CVSS)
        cvss_vector = vulnerability.get('cvss_vector', '')
        av = self._extract_metric(cvss_vector, 'AV')
        features['attack_vector'] = {
            'N': 1.0,  # Network
            'A': 0.6,  # Adjacent
            'L': 0.3,  # Local
            'P': 0.1,  # Physical
        }.get(av, 0.5)

        # Attack complexity
        ac = self._extract_metric(cvss_vector, 'AC')
        features['attack_complexity'] = {
            'L': 1.0,  # Low
            'H': 0.3,  # High
        }.get(ac, 0.5)

        # Privileges required
        pr = self._extract_metric(cvss_vector, 'PR')
        features['privileges_required'] = {
            'N': 1.0,  # None
            'L': 0.6,  # Low
            'H': 0.2,  # High
        }.get(pr, 0.5)

        # Vulnerability age
        published = vulnerability.get('published_date')
        if published:
            if isinstance(published, str):
                published_date = datetime.fromisoformat(published.replace('Z', '+00:00'))
            else:
                published_date = published

            age_days = (datetime.utcnow() - published_date.replace(tzinfo=None)).days
            # Newer vulnerabilities (0-30 days) get higher score
            features['vulnerability_age'] = max(0.0, 1.0 - (age_days / 365.0))
        else:
            features['vulnerability_age'] = 0.5

        return features

    def _calculate_exploit_probability(
        self,
        features: dict[str, float],
    ) -> float:
        """Calculate exploit probability using weighted features"""
        probability = 0.0

        for feature_name, feature_value in features.items():
            weight = self.FEATURE_WEIGHTS.get(feature_name, 0.0)
            probability += feature_value * weight

        # Apply sigmoid function for smooth probability curve
        probability = 1.0 / (1.0 + math.exp(-5.0 * (probability - 0.5)))

        return min(1.0, max(0.0, probability))

    def _estimate_weaponization_timeline(
        self,
        features: dict[str, float],
    ) -> int | None:
        """Estimate days until exploit weaponization"""
        # If exploit already exists
        if features.get('public_exploits', 0.0) > 0:
            return 0

        # If in CISA KEV
        if features.get('cisa_kev', 0.0) > 0:
            return 0

        # Base timeline (days)
        base_timeline = 90

        # Adjust based on attack complexity
        ac_factor = 1.0 / max(features.get('attack_complexity', 0.5), 0.1)

        # Adjust based on CVSS score (higher = faster)
        cvss_factor = features.get('cvss_score', 0.5) + 0.5

        # Adjust based on attack vector (network = faster)
        av_factor = features.get('attack_vector', 0.5) + 0.5

        timeline = base_timeline / (ac_factor * cvss_factor * av_factor)

        return max(1, int(timeline))

    def _parse_cvss_vector(self, vector: str) -> dict[str, str]:
        """Parse CVSS vector string"""
        metrics = {
            'attack_vector': 'UNKNOWN',
            'attack_complexity': 'UNKNOWN',
            'privileges_required': 'UNKNOWN',
            'user_interaction': 'UNKNOWN',
            'scope': 'UNKNOWN',
        }

        if not vector:
            return metrics

        av = self._extract_metric(vector, 'AV')
        metrics['attack_vector'] = {
            'N': 'NETWORK',
            'A': 'ADJACENT',
            'L': 'LOCAL',
            'P': 'PHYSICAL',
        }.get(av, 'UNKNOWN')

        ac = self._extract_metric(vector, 'AC')
        metrics['attack_complexity'] = {
            'L': 'LOW',
            'H': 'HIGH',
        }.get(ac, 'UNKNOWN')

        pr = self._extract_metric(vector, 'PR')
        metrics['privileges_required'] = {
            'N': 'NONE',
            'L': 'LOW',
            'H': 'HIGH',
        }.get(pr, 'UNKNOWN')

        ui = self._extract_metric(vector, 'UI')
        metrics['user_interaction'] = {
            'N': 'NONE',
            'R': 'REQUIRED',
        }.get(ui, 'UNKNOWN')

        return metrics

    def _extract_metric(self, vector: str, metric: str) -> str:
        """Extract specific metric from CVSS vector"""
        pattern = rf'{metric}:(\w)'
        match = re.search(pattern, vector)
        return match.group(1) if match else ''

    def _calculate_risk_score(
        self,
        exploit_prob: float,
        features: dict[str, float],
        attack_metrics: dict[str, str],
    ) -> float:
        """Calculate comprehensive risk score (0-100)"""
        # Base score from exploit probability
        risk = exploit_prob * 100.0

        # Boost for high CVSS
        if features.get('cvss_score', 0.0) > 0.8:
            risk *= 1.2

        # Boost for network accessibility
        if attack_metrics.get('attack_vector') == 'NETWORK':
            risk *= 1.15

        # Boost for no privileges required
        if attack_metrics.get('privileges_required') == 'NONE':
            risk *= 1.1

        # Boost for active exploitation
        if features.get('cisa_kev', 0.0) > 0:
            risk *= 1.3

        return min(100.0, risk)

    def _calculate_prediction_confidence(
        self,
        features: dict[str, float],
    ) -> float:
        """Calculate confidence in prediction"""
        # More features available = higher confidence
        available_features = sum(1 for v in features.values() if v > 0)
        total_features = len(self.FEATURE_WEIGHTS)

        confidence = available_features / total_features

        # Boost confidence if we have threat intel
        if features.get('epss_score', 0.0) > 0:
            confidence *= 1.2

        if features.get('cisa_kev', 0.0) > 0:
            confidence *= 1.2

        return min(1.0, confidence)


class ReachabilityAnalyzer:
    """
    Vulnerability reachability analyzer

    Analyzes whether vulnerable code paths are actually reachable in the
    application, reducing false positives.
    """

    def analyze_reachability(
        self,
        package_name: str,
        vulnerable_function: str | None,
        dependency_graph: dict[str, list[str]],
        call_graph: dict[str, list[str]] | None = None,
    ) -> ReachabilityAnalysis:
        """
        Analyze if vulnerable package/function is reachable

        Args:
            package_name: Name of vulnerable package
            vulnerable_function: Specific vulnerable function (if known)
            dependency_graph: Package dependency graph
            call_graph: Optional function call graph

        Returns:
            ReachabilityAnalysis with results
        """
        # Check if package is direct dependency
        direct_usage = package_name in dependency_graph.get('direct', [])

        # Calculate transitive depth
        transitive_depth = self._calculate_depth(
            package_name,
            dependency_graph,
        )

        # Calculate impact radius (number of dependents)
        impact_radius = len(self._find_dependents(package_name, dependency_graph))

        # Analyze call paths
        is_reachable = False
        call_path = []
        confidence = "UNKNOWN"

        if call_graph and vulnerable_function:
            call_path = self._find_call_path(
                vulnerable_function,
                call_graph,
            )
            is_reachable = len(call_path) > 0
            confidence = "HIGH" if is_reachable else "MEDIUM"
        elif direct_usage:
            is_reachable = True
            confidence = "MEDIUM"
        else:
            is_reachable = True  # Conservative: assume reachable
            confidence = "LOW"

        # Calculate execution probability
        execution_prob = self._calculate_execution_probability(
            direct_usage,
            transitive_depth,
            len(call_path),
        )

        return ReachabilityAnalysis(
            package_name=package_name,
            is_reachable=is_reachable,
            confidence=confidence,
            call_path=call_path,
            execution_probability=execution_prob,
            impact_radius=impact_radius,
            direct_usage=direct_usage,
            transitive_depth=transitive_depth,
        )

    def _calculate_depth(
        self,
        package: str,
        dep_graph: dict[str, list[str]],
        depth: int = 0,
        visited: set[str] | None = None,
    ) -> int:
        """Calculate depth of package in dependency tree"""
        if visited is None:
            visited = set()

        if package in visited:
            return depth

        visited.add(package)

        # If package is direct dependency
        if package in dep_graph.get('direct', []):
            return 0

        # Find minimum depth through all paths
        min_depth = float('inf')
        for parent, children in dep_graph.items():
            if package in children:
                parent_depth = self._calculate_depth(parent, dep_graph, depth + 1, visited)
                min_depth = min(min_depth, parent_depth + 1)

        return int(min_depth) if min_depth != float('inf') else depth

    def _find_dependents(
        self,
        package: str,
        dep_graph: dict[str, list[str]],
    ) -> list[str]:
        """Find all packages that depend on this package"""
        dependents = []

        for parent, children in dep_graph.items():
            if package in children:
                dependents.append(parent)

        return dependents

    def _find_call_path(
        self,
        target_function: str,
        call_graph: dict[str, list[str]],
        max_depth: int = 10,
    ) -> list[str]:
        """Find call path to target function using BFS"""
        from collections import deque

        # BFS to find shortest path
        queue = deque([('main', ['main'])])
        visited = set()

        while queue:
            current, path = queue.popleft()

            if len(path) > max_depth:
                continue

            if current in visited:
                continue

            visited.add(current)

            # Check if we reached target
            if current == target_function:
                return path

            # Explore callees
            for callee in call_graph.get(current, []):
                queue.append((callee, path + [callee]))

        return []

    def _calculate_execution_probability(
        self,
        direct_usage: bool,
        transitive_depth: int,
        call_path_length: int,
    ) -> float:
        """Calculate probability that vulnerable code is executed"""
        probability = 1.0

        # Reduce probability for indirect dependencies
        if not direct_usage:
            probability *= 0.5

        # Reduce based on transitive depth
        probability *= (0.9 ** transitive_depth)

        # Reduce based on call path length
        if call_path_length > 0:
            probability *= (0.95 ** call_path_length)
        else:
            # No call path found, reduce significantly
            probability *= 0.3

        return max(0.0, min(1.0, probability))


if __name__ == "__main__":
    import json
    import sys

    def main():
        # Example usage
        predictor = ExploitPredictor()

        # Example vulnerability
        vuln = {
            'cve_id': 'CVE-2024-1234',
            'cvss_score': 9.8,
            'cvss_vector': 'CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H',
            'published_date': '2024-01-15T00:00:00Z',
        }

        # Example threat intel
        threat_intel = {
            'epss_score': 0.75,
            'exploits': [{'type': 'poc'}],
            'known_exploited': False,
        }

        prediction = predictor.predict_exploitation(vuln, threat_intel)

        print("=== Exploit Prediction ===")
        print(json.dumps(prediction.to_dict(), indent=2))

    if len(sys.argv) > 1:
        main()
